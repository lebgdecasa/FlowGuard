{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6252e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    from imblearn.combine import SMOTETomek\n",
    "    IMBALANCED_LEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: imbalanced-learn not available. Install with: pip install imbalanced-learn\")\n",
    "    IMBALANCED_LEARN_AVAILABLE = False\n",
    "\n",
    "\n",
    "\n",
    "# Download selected version\n",
    "path = kagglehub.dataset_download(\"agungpambudi/network-malware-detection-connection-analysis/versions/1\")\n",
    "# Define the path where files were extracted\n",
    "dataset_path = \"/Users/ayda/.cache/kagglehub/datasets/agungpambudi/network-malware-detection-connection-analysis/versions/1\"\n",
    "\n",
    "# List files in that directory\n",
    "files = os.listdir(dataset_path)\n",
    "print(\"Files in dataset folder:\", files)\n",
    "\n",
    "# Assuming there's one large CSV (you can adjust this if needed)\n",
    "csv_file = next((f for f in files if f.endswith(\".csv\")), None)\n",
    "\n",
    "# Read the CSV (pipe-separated, as in CTU datasets)\n",
    "data = pd.read_csv(os.path.join(dataset_path, csv_file), sep='|', low_memory=False)\n",
    "\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "drop_cols = ['uid', 'history', 'tunnel_parents', 'detailed-label', 'local_resp', 'local_orig', 'missed_bytes']\n",
    "data.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "data.dropna(subset=['label', 'proto', 'service', 'duration', 'orig_bytes', 'resp_bytes'], inplace=True)\n",
    "\n",
    "\n",
    "for col in ['duration', 'orig_bytes', 'resp_bytes']:\n",
    "    data[col] = data[col].replace('-', np.nan)  # Replace '-' with NaN\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')  # Convert to numeric\n",
    "    data[col].fillna(0, inplace=True)  # Replace NaNs with 0\n",
    "\n",
    "\n",
    "data['proto'] = data['proto'].astype('category').cat.codes\n",
    "data['service'] = data['service'].astype('category').cat.codes\n",
    "\n",
    "\n",
    "data['label'] = data['label'].apply(lambda x: 0 if x == 'Benign' else 1)\n",
    "\n",
    "\n",
    "features = ['proto', 'service', 'duration', 'orig_bytes', 'resp_bytes']\n",
    "X = data[features]\n",
    "y = data['label']\n",
    "\n",
    "\n",
    "print(\"=== DATA BALANCE ANALYSIS ===\")\n",
    "class_distribution = Counter(y)\n",
    "print(f\"Class distribution: {class_distribution}\")\n",
    "print(f\"Class 0 (Benign): {class_distribution[0]} ({class_distribution[0]/len(y)*100:.2f}%)\")\n",
    "print(f\"Class 1 (Malicious): {class_distribution[1]} ({class_distribution[1]/len(y)*100:.2f}%)\")\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "minority_class = min(class_distribution.values())\n",
    "majority_class = max(class_distribution.values())\n",
    "imbalance_ratio = majority_class / minority_class\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "\n",
    "is_imbalanced = imbalance_ratio > 2.0\n",
    "print(f\"Dataset is {'imbalanced' if is_imbalanced else 'balanced'}\")\n",
    "\n",
    "\n",
    "X_balanced, y_balanced = X.copy(), y.copy()\n",
    "\n",
    "if is_imbalanced and IMBALANCED_LEARN_AVAILABLE:\n",
    "    print(\"\\n=== APPLYING DATA BALANCING ===\")\n",
    "    \n",
    "    \n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_balanced, y_balanced = smote.fit_resample(X, y)\n",
    "    \n",
    "    \n",
    "    print(\"Balancing method used: SMOTE\")\n",
    "    balanced_distribution = Counter(y_balanced)\n",
    "    print(f\"Balanced class distribution: {balanced_distribution}\")\n",
    "    print(f\"New dataset size: {len(y_balanced)} (original: {len(y)})\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(balanced_distribution.keys(), balanced_distribution.values())\n",
    "    plt.title('Balanced Class Distribution (SMOTE)')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "elif is_imbalanced and not IMBALANCED_LEARN_AVAILABLE:\n",
    "    print(\"\\n=== MANUAL BALANCING (Simple Random Oversampling) ===\")\n",
    "    # Simple manual balancing if imbalanced-learn is not available\n",
    "    minority_class_label = 0 if class_distribution[0] < class_distribution[1] else 1\n",
    "    majority_class_label = 1 - minority_class_label\n",
    "    \n",
    "    # Get indices for each class\n",
    "    minority_indices = y[y == minority_class_label].index\n",
    "    majority_indices = y[y == majority_class_label].index\n",
    "    \n",
    "    # Oversample minority class\n",
    "    n_samples_needed = len(majority_indices) - len(minority_indices)\n",
    "    oversampled_indices = np.random.choice(minority_indices, n_samples_needed, replace=True)\n",
    "    \n",
    "    # Combine all indices\n",
    "    balanced_indices = np.concatenate([majority_indices, minority_indices, oversampled_indices])\n",
    "    \n",
    "    # Create balanced dataset\n",
    "    X_balanced = X.iloc[balanced_indices].reset_index(drop=True)\n",
    "    y_balanced = y.iloc[balanced_indices].reset_index(drop=True)\n",
    "    \n",
    "    print(\"Balancing method used: Random Oversampling\")\n",
    "    balanced_distribution = Counter(y_balanced)\n",
    "    print(f\"Balanced class distribution: {balanced_distribution}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73616a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, stratify=y_balanced, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n=== CROSS-VALIDATION ANALYSIS ===\")\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(clf, X_balanced, y_balanced, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Additional cross-validation metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "cv_results = cross_validate(\n",
    "    clf, X_balanced, y_balanced, cv=cv, \n",
    "    scoring=['accuracy', 'precision', 'recall', 'f1'], \n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "print(f\"CV Accuracy: {cv_results['test_accuracy'].mean():.4f} (+/- {cv_results['test_accuracy'].std() * 2:.4f})\")\n",
    "print(f\"CV Precision: {cv_results['test_precision'].mean():.4f} (+/- {cv_results['test_precision'].std() * 2:.4f})\")\n",
    "print(f\"CV Recall: {cv_results['test_recall'].mean():.4f} (+/- {cv_results['test_recall'].std() * 2:.4f})\")\n",
    "print(f\"CV F1-score: {cv_results['test_f1'].mean():.4f} (+/- {cv_results['test_f1'].std() * 2:.4f})\")\n",
    "\n",
    "\n",
    "print(\"\\n=== FINAL MODEL TRAINING ===\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Test Set Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\n=== DETAILED EVALUATION ===\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
